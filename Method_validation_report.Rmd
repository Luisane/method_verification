---
title: "GSP Method Verification"
author: Sven Eberhard, Amy Chambers and Matthew Henderson
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
    pdf_document:
        keep_tex: false
        includes:
            in_header: ../resources/header.tex
        fig_caption: yes
        number_sections: yes
fontsize: 11pt 
geometry: margin=1in
params:
    analyte: 
        label: "Analyte:"
        value: "TSH"
        input: select
        choices: [TSH, N17P, IRT]
    file: 
        label: "Input dataset:"
        value: ./data/N17P_GSP_validation.xls
        input: text
---

\centering
\includegraphics[width = 60mm]{../resources/NSO_logo.pdf}
\raggedright
\tableofcontents 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=TRUE, warning=FALSE, fig.height=4, fig.width=6)
```

```{r}
library("dplyr")
library("magrittr")
library("ggplot2")
library("tidyr")
library("mcr")
library("readxl")
library("pander")
library("qcc")

## Used for testing
## params <- list(analyte = "N17P", file = "../data/N17P_GSP_validation.xls")
## params <- list(analyte = "IRT", file = "../data/IRT_GSP_validation.xls")
                 
## set analyte_info dependant on analyte
 info <- switch(params$analyte,
                "TSH" = list(units = "mIU/L", threshold = 17, lower = 1.31, upper = 250, trim = 40),
                "N17P" = list(units = "nmol/L", threshold = 38, lower = 0, upper = 299.2, trim = 60),
                "IRT" = list(units = "ng/ml", threshold = c(48,117.5), lower = 9, upper = 500, trim = 100))

## excel workbook sheets
sheets <- list(comp = 1, precision = 2, prelim = 3, linearity = 4, lob = 5)

## getwd()
## N17OHP ng/mL -> nmol/L conversion factor 1.36
## N17OHP 1.4ng/mL to 220ng/mL
## N17OHP 1.904 nmol/L to 299.2 nmol/L
## NTSH 1.31uU/mL to 250uU/mL
## IRT 9ng/ml to 500ng/mL
```

# Background

# Methods

# Recommendations

## Sample type

## Sample stability

## Analytical Measurement Range

Analytical measurement range (AMR) is determined by the manufacturer for each kit lot. The AMR for the kit lot used in this validation is 

# Precision Study #

## Preliminary Precision ##

```{r}
prelim <- read_xls(params$file, sheet = sheets$prelim)

##### Functions for preliminary precision
### 20 repeats of QC material on the same day

prelim %>%
    gather(level, result, level1:level3) %>%
    group_by(instrument,level) %>%
    summarize(n = n(),
              mean = mean(result),
              sd = sd(result),
              cv = sd/mean *100) %>%
    pander::pander()
```

## Within and Between Run Precision ##

Five runs with three repetitions each were done to provide within-run
and between-run precision data. Analysis follows the calculations and
examples described in cite:Krouwer1984.  The data collection was
carried out at three levels, the results are presented in tables

Total imprecision was determined by pooling the variances of the
within and between day runs. Repeatability (aka: within-run precision)
was determined from within run replicates according to CLSI
guidelines. Total imprecision was compared against the manufacturer
claim.


```{r}
precision <- read_xls(params$file, sheet = sheets$precision)

# QC distribution
precision %>%
    gather(rep, result, rep1:rep3) %>%
    ggplot(aes(result, fill = factor(level))) +
    geom_density(alpha = 0.5) +
    facet_grid(instrument~.) +
    xlab(paste(params$analyte, info$units)) +
    scale_fill_discrete("Level")

``` 

```{r}
# Pseudo LJ charts
precision %>%
    gather(rep, result, rep1:rep3) %>%
    ggplot(aes(x = run, y = result, colour= factor(instrument))) +
    geom_point() +
    stat_summary(fun.y=mean, geom="line") +
    stat_summary(fun.data = mean_se, geom = "errorbar") +
    facet_grid(level~., scales = "free_y") +
    xlab("Run") +
    ylab(info$units) + 
    scale_colour_discrete("Instrument")

``` 

\clearpage

```{r}
## Within-run imprecision
within <- precision %>%
    gather(rep, result, rep1:rep3) %>%
    group_by(instrument, level, run) %>%
    summarize(n = n(),
              mean = mean(result),
              var = var(result)) %>%
    group_by(instrument, level) %>%
    summarize(n = sum(n),
              mean = mean(mean),
              var_within = mean(var))
              
## Between-run imprecision
between <- precision %>%
    gather(rep, result, rep1:rep3) %>%
    group_by(instrument, level, run) %>%
    summarize(n = n(),
              mean = mean(result)) %>%
    group_by(instrument, level) %>%
    summarize(n = sum(n),
              var_btwn = var(mean))
              

## Total imprecision
within$var_btwn <- between$var_btwn

within %>%
    group_by(instrument, level) %>%
    summarize(mean = mean,
              sd_within = sqrt(var_within),
              sd_btwn = sqrt(var_btwn),
              sd_total = sqrt(var_within + var_btwn)) %>%
    pander::pander()

```
 
# Analytical Measurement Range #

## Linearity ##

```{r}
linearity <- read_xls(params$file, sheet = sheets$linearity)

linearity %>%
    ggplot(aes(x=target, y=result)) +
    geom_point(colour = 'black') +
    scale_colour_hue(name="Models", labels=c('1st','2nd','3rd')) +
    geom_smooth(aes(colour = 'red'), method = 'lm',
                formula = 'y ~ x') +
    geom_smooth(aes(colour = 'blue'), method = 'lm',
                formula = 'y ~ poly(x,2)') +
    geom_smooth(aes(colour = 'green'), method = 'lm',
                formula = 'y ~ poly(x,3)') +
    facet_wrap(~ instrument) +
    xlab(paste(params$analyte,"calibrator", info$units)) +
    ylab(info$units)
``` 


## Limit of Blank

\[
LoB = \bar{x}_{blank} + 1.645(SD_{blank})
\]

```{r}
lob <- read_xls(params$file, sheet = sheets$lob)

# QC distribution
lob %>%
    ggplot(aes(result, fill = factor(instrument))) +
    geom_density(alpha = 0.5) +
    facet_grid(instrument~.) +
    xlab(paste(params$analyte, info$units)) +
    scale_fill_discrete("Instrument")

``` 


```{r}
lob %>%
    group_by(instrument) %>%
    summarize(n = n(),
              mean = mean(result),
              sd = sd(result),
              lob = mean + 1.645*sd) %>%
    pander::pander()
              
``` 


# Comparison # 

## Data Summary ##

```{r}
comp <- read_xls(params$file, sheet = params$comp)
comp$GSP <- gsub(pattern="<|>",replacement="", x=comp$GSP, perl = TRUE) ## remove <,>
comp$GSP <- as.numeric(comp$GSP)
comp %<>%
    na.omit() %>%
    filter(GSP > info$lower)

pander::pander(summary(comp[, c("AD", "GSP")]))
```

```{r, fig.cap="\\label{fig:dens}Density plot for the method comparison"}
  comp %>%
      gather(method, result, AD:GSP) %>%
      ggplot(aes(result, fill = method)) +
      geom_density(alpha = 0.5) +
      xlab(paste(params$analyte, info$units)) +
      scale_fill_discrete(name = "Method")
   
  # labs(title = "Density plot for the TSH reagent lot comparison")
```
```{r, fig.cap="\\label{fig:dens_inst}Density plot for the method comparison by instrument"}
comp %>%
      gather(method, result, AD:GSP) %>%
      ggplot(aes(result, fill = method)) +
      geom_density(alpha = 0.5) +
      facet_grid(instrument ~.) +
      xlab(paste(params$analyte, info$units)) +
      scale_fill_discrete(name = "Method")

``` 

\clearpage

### Paired T-test ###

```{r}
pander::pander(t.test(comp$AD, comp$GSP, paired = TRUE),
                   caption = "\\label{tab:paired}Paired T-test")
```

\clearpage

### Regression Analysis ###

```{r, fig.cap="\\label{fig:dem}Deming regression"}
comp.deming <- mcreg(x = comp$AD, y =comp$GSP, error.ratio = 1, alpha = 0.05,
                     mref.name = "AD", mtest.name = "GSP", sample.names = NULL,
                     method.reg = "Deming", method.ci = "bootstrap",
                     method.bootstrap.ci = "BCa",
                     nsamples = 999, rng.seed = NULL, rng.kind = "Mersenne-Twister", iter.max = 30,
                     threshold = 1e-06, na.rm = TRUE, NBins = 1e+06)

plot(comp.deming, x.lab = "AD", y.lab = "GSP", main=paste("Pooled", params$analyte,"Method Comparision"))
```

```{r, fig.cap="\\label{fig:dem_inst}Deming regression for instrument"}
for (inst in c(344, 348, 349)){
comp_inst<- comp %>%
    filter(instrument == inst)

comp_inst.deming <- mcreg(x = comp_inst$AD, y =comp_inst$GSP, error.ratio = 1, alpha = 0.05,
                     mref.name = "AD", mtest.name = "GSP", sample.names = NULL,
                     method.reg = "Deming", method.ci = "bootstrap",
                     method.bootstrap.ci = "BCa",
                     nsamples = 999, rng.seed = NULL, rng.kind = "Mersenne-Twister", iter.max = 30,
                     threshold = 1e-06, na.rm = TRUE, NBins = 1e+06)

plot(comp_inst.deming, x.lab = "AD", y.lab = "GSP", main=paste(inst, params$analyte, "Method Comparision" ))
}
```

* The data set was filtered to remove values greater than `r info$upper`.

```{r, fig.cap="\\label{fig:dem}Filtered Deming regression"}
trim <- comp %>%
     filter(AD <= info$trim & GSP <= info$trim)

trim.deming <- mcreg(x = trim$AD, y =trim$GSP, error.ratio = 1, alpha = 0.05,
                     mref.name = "AD", mtest.name = "GSP", sample.names = NULL,
                     method.reg = "Deming", method.ci = "bootstrap",
                     method.bootstrap.ci = "BCa",
                     nsamples = 999, rng.seed = NULL, rng.kind = "Mersenne-Twister", iter.max = 30,
                     threshold = 1e-06, na.rm = TRUE, NBins = 1e+06)

plot(trim.deming, x.lab = "Old", y.lab = "New", main=paste(params$analyte, "Filtered Method Comparision"))
```

```{r}    
pander::pander(trim.deming@para, caption = "\\label{tab:para}Regression Parameters")
```

```{r,fig.cap="\\label{fig:diff}Difference Plot"}
plotDifference(trim.deming, main= paste(params$analyte, "Method Comparision"))
```
\clearpage

### Screening Thresholds ###
 

* The regression parameters (table \ref{tab:para}) were used to
  determine the effect of the GSP method  on the screening threshold.

```{r}
intercept <- trim.deming@para[1,1] # intercept
slope <- trim.deming@para[2,1] # slope

reg <- function(m,x,b){
      y <- m * x + b
      return(round(y, digits = 3))
}
```

* A `r params$analyte` result of `r reg(slope, info$threshold,
  intercept)` `r info$units` on the GSP platform is equivalent to a
  value at the screening threshold (`r info$threshold` `r info$units`)
  with the AutoDelfia.

\clearpage

# Interference # 

## EDTA study ##

* We are using disodium EDTA dihydrate
    * FW = 372.24 g/mol

* In a full EDTA tube there is 1.8 mg EDTA per millilitre of blood,
  this is equivalent to:
    * x mg/ml = 372.24 mg/mmol * 1/1000  L/ml
    * x = 0.37224 (mmol/L)/(mg/ml)
    * 1.8 mg/ml * 0.37224 (mmol/L)/(mg/ml) = 0.670032 mmol/L
    
* Make a 100 ml 0.5M EDTA stock:
    * 372.24 g/mol * 0.5 mol/L * 100 ml/1000 ml/L =  18.6 g
    * 18.6 g up to 100 ml of water
    * EDTA will go into solution at pH 8.0
    * add NaOH pellet to pH 8.0 
    
* Create a working solution of 100 mM EDTA
    * 200 ul 0.5 M EDTA + 800 ul water 
* Create a serial dilution:
  * 50 mmol/L = 500 ul (100mM EDTA) + 500 ul Water
  * 25 mmol/L = 500 ul (50mM EDTA) + 500 ul Water
  * 12.5 mmol/L = 500 ul (25mM EDTA) + 500 ul Water
  * 6.25 mmol/L = 500 ul (12.5mM EDTA) + 500 ul Water
  * 3.125 mmol/L = 500 ul (6.2mM EDTA) + 500 ul Water

* Add 75 ul of each concentration to the filter paper cards:

  
\clearpage
